{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bad08e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration Cell - Add this at the top of each notebook\n",
    "import os\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Detect environment\n",
    "IS_KAGGLE = os.path.exists('/kaggle/input')\n",
    "IS_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "# Set base directories based on environment\n",
    "if IS_KAGGLE:\n",
    "    INPUT_ROOT = \"/kaggle/input\"\n",
    "    WORK_DIR = \"/kaggle/working\"\n",
    "elif IS_COLAB:\n",
    "    INPUT_ROOT = \"/content/input\"\n",
    "    WORK_DIR = \"/content/working\"\n",
    "else:\n",
    "    # Local environment\n",
    "    INPUT_ROOT = Path.cwd() / \"input\"\n",
    "    WORK_DIR = Path.cwd() / \"working\"\n",
    "\n",
    "# Create standard directories\n",
    "OUT_DIR = os.path.join(WORK_DIR, \"data\")\n",
    "EXPERIMENTS_DIR = os.path.join(WORK_DIR, \"experiments\")\n",
    "SCRIPTS_DIR = os.path.join(WORK_DIR, \"scripts\")\n",
    "\n",
    "# Create all directories\n",
    "for directory in [OUT_DIR, EXPERIMENTS_DIR, SCRIPTS_DIR]:\n",
    "    Path(directory).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Environment: {'Kaggle' if IS_KAGGLE else 'Colab' if IS_COLAB else 'Local'}\")\n",
    "print(f\"Input directory: {INPUT_ROOT}\")\n",
    "print(f\"Working directory: {WORK_DIR}\")\n",
    "print(f\"Data directory: {OUT_DIR}\")\n",
    "print(f\"Experiments directory: {EXPERIMENTS_DIR}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e238373a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Read from Jigsaw dataset -> Clean -> Binarize -> Remove duplicates -> partitioning -> Export CSV\n",
    "import os, re, json\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "INPUT_ROOT = \"/kaggle/input\"\n",
    "WORK_DIR   = \"/kaggle/working\"\n",
    "OUT_DIR    = os.path.join(WORK_DIR, \"data\")\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "# Automatically locate Jigsaw dataset\n",
    "JIGSAW_DIRS = [os.path.join(INPUT_ROOT, d) for d in os.listdir(INPUT_ROOT)\n",
    "               if d.startswith(\"jigsaw-unintended-bias-in-toxicity-classification\")]\n",
    "assert len(JIGSAW_DIRS) >= 1, \"The jigsaw dataset was not found.\"\n",
    "JIGSAW_DIR = JIGSAW_DIRS[0]\n",
    "\n",
    "# Identity columns\n",
    "IDENTITY_COLS = [\n",
    "    \"male\",\"female\",\"transgender\",\"other_gender\",\n",
    "    \"black\",\"white\",\"asian\",\"latino\",\"other_race_or_ethnicity\",\n",
    "    \"christian\",\"jewish\",\"muslim\",\"hindu\",\"buddhist\",\"atheist\",\"other_religion\",\n",
    "    \"heterosexual\",\"homosexual_gay_or_lesbian\",\"bisexual\",\"other_sexual_orientation\",\n",
    "    \"physical_disability\",\"intellectual_or_learning_disability\",\"psychiatric_or_mental_illness\",\"other_disability\"\n",
    "]\n",
    "\n",
    "# Read the original train.csv file\n",
    "train_path = os.path.join(JIGSAW_DIR, \"train.csv\")\n",
    "df_raw = pd.read_csv(train_path)\n",
    "\n",
    "# Text cleaning\n",
    "URL_RE = re.compile(r\"http\\S+\")\n",
    "AT_RE  = re.compile(r\"@\\w+\")\n",
    "def clean_text(s: str) -> str:\n",
    "    s = str(s) if pd.notna(s) else \"\"\n",
    "    s = URL_RE.sub(\" URL \", s)\n",
    "    s = AT_RE .sub(\"@USER\", s)\n",
    "    s = s.replace(\"\\n\", \" \").replace(\"\\t\", \" \")\n",
    "    s = re.sub(r\"\\s+\", \" \", s).strip()\n",
    "    return s\n",
    "\n",
    "use_id_cols = [c for c in IDENTITY_COLS if c in df_raw.columns]\n",
    "df = pd.DataFrame({\n",
    "    \"id\": df_raw[\"id\"],\n",
    "    \"text\": df_raw[\"comment_text\"].map(clean_text),\n",
    "    # Jigsaw target âˆˆ [0,1], Binarize by 0.5\n",
    "    \"label\": (df_raw[\"target\"] >= 0.5).astype(int)\n",
    "})\n",
    "for c in use_id_cols:\n",
    "    df[f\"g_{c}\"] = (df_raw[c].fillna(0) >= 0.5).astype(int)\n",
    "\n",
    "# Deduplicate (by text)\n",
    "df = df.drop_duplicates(subset=[\"text\"]).reset_index(drop=True)\n",
    "\n",
    "# Stratified 8/1/1 \n",
    "sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "train_idx, temp_idx = next(sss1.split(df, df[\"label\"]))\n",
    "temp = df.iloc[temp_idx]\n",
    "sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "val_rel_idx, test_rel_idx = next(sss2.split(temp, temp[\"label\"]))\n",
    "val_idx  = temp_idx[val_rel_idx]\n",
    "test_idx = temp_idx[test_rel_idx]\n",
    "\n",
    "print(f\"Train: {len(train_idx)}, Val: {len(val_idx)}, Test: {len(test_idx)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500ace62",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Export standard CSV files (text, label only) for training\n",
    "df.iloc[train_idx][[\"text\",\"label\"]].to_csv(os.path.join(OUT_DIR, \"jigsaw_train.csv\"), index=False)\n",
    "df.iloc[val_idx  ][[\"text\",\"label\"]].to_csv(os.path.join(OUT_DIR, \"jigsaw_val.csv\"  ), index=False)\n",
    "df.iloc[test_idx ][[\"text\",\"label\"]].to_csv(os.path.join(OUT_DIR, \"jigsaw_test.csv\" ), index=False)\n",
    "\n",
    "print(\"Standard CSVs (text, label) exported.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecad6543",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Export full CSV files (with id and group attributes) for fairness analysis\n",
    "group_cols = [\"id\", \"text\", \"label\"] + [f\"g_{c}\" for c in use_id_cols]\n",
    "df.iloc[train_idx][group_cols].to_csv(os.path.join(OUT_DIR, \"jigsaw_train_full.csv\"), index=False)\n",
    "df.iloc[val_idx  ][group_cols].to_csv(os.path.join(OUT_DIR, \"jigsaw_val_full.csv\"  ), index=False)\n",
    "df.iloc[test_idx ][group_cols].to_csv(os.path.join(OUT_DIR, \"jigsaw_test_full.csv\" ), index=False)\n",
    "\n",
    "print(\"Full CSVs (with id and group attributes) exported.\")\n",
    "print(f\"Group columns included: {len(use_id_cols)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a39db1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Save protocols\n",
    "splits = {\n",
    "    \"jigsaw\": {\n",
    "        \"train_n\": int(len(train_idx)),\n",
    "        \"val_n\": int(len(val_idx)),\n",
    "        \"test_n\": int(len(test_idx)),\n",
    "        \"pos_rate\": {\n",
    "            \"train\": float(df.iloc[train_idx][\"label\"].mean()),\n",
    "            \"val\":   float(df.iloc[val_idx][\"label\"].mean()),\n",
    "            \"test\":  float(df.iloc[test_idx][\"label\"].mean()),\n",
    "        }\n",
    "    }\n",
    "}\n",
    "with open(os.path.join(OUT_DIR, \"protocols.json\"), \"w\") as f:\n",
    "    json.dump(splits, f, indent=2)\n",
    "\n",
    "print(\"Export complete:\", OUT_DIR)\n",
    "!ls -lh {OUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f36391a6",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa9d4390",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a653596",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
